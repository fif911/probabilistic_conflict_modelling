{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab71d4c-de00-470c-a92b-410102021502",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc96c2d7f86bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from ngboost.scores import CRPScore, LogScore\n",
    "from ngboost.distns import Poisson, Normal, MultivariateNormal\n",
    "from ngboost import NGBRegressor\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import CRPS.CRPS as pscore\n",
    "import shap\n",
    "\n",
    "from utilities.views_utils import views_month_id_to_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290181d381d328ff",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad61fc8275db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "prediction_year: int = 2024\n",
    "prediction_window: int = 14\n",
    "cm_features_version: str = \"2.5\"\n",
    "\n",
    "# Run config\n",
    "SHOW_PLOTS: bool = True\n",
    "PLOT_STD: bool = True\n",
    "SAVE_FIGURES: bool = True\n",
    "USE_CACHED_MODEL: bool = True\n",
    "SAVE_PREDICTIONS: bool = True\n",
    "\n",
    "# Data preparation settings\n",
    "INCLUDE_COUNTRY_ID: bool = True\n",
    "INCLUDE_MONTH_ID: bool = True\n",
    "DROP_0_ROWS_PERCENT: int = 20\n",
    "DROP_35_LEAST_IMPORTANT: bool = False\n",
    "LOG_TRANSFORM: bool = False\n",
    "\n",
    "# Model settings\n",
    "dist = Normal\n",
    "score = CRPScore\n",
    "n_estimators: int = 300\n",
    "bs_max_depth: int = 5\n",
    "minibatch_frac: float = 0.5\n",
    "base_learner = DecisionTreeRegressor(\n",
    "    criterion=\"friedman_mse\",\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=bs_max_depth,\n",
    "    splitter=\"best\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f531d1cd21222e",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd14c2336fed604",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_str: str = (\n",
    "    f\"ng_boost_cm_v{cm_features_version}_\"\n",
    "    f\"pw_{prediction_window}_\"\n",
    "    f\"{dist.__name__.lower()}_\"\n",
    "    f\"d_{DROP_0_ROWS_PERCENT}_\"\n",
    "    f\"n_{n_estimators}_\"\n",
    "    f\"s_{score.__name__.lower()}_\"\n",
    "    f\"c_{str(INCLUDE_COUNTRY_ID)[0]}_\"\n",
    "    f\"m_{str(INCLUDE_MONTH_ID)[0]}_\"\n",
    "    f\"bsd_{bs_max_depth}_\"\n",
    "    f\"mbf_{minibatch_frac}_\"\n",
    "    f\"dli_{35 if DROP_35_LEAST_IMPORTANT else 0}_\"\n",
    "    f\"log_{str(LOG_TRANSFORM)[0]}\"\n",
    ")\n",
    "\n",
    "model_cache_prefix: str = f\"../model_cache/{folder_to_str}/window=Y{prediction_year}\"\n",
    "figures_prefix: str = f\"../figures/{folder_to_str}/window=Y{prediction_year}\"\n",
    "submission_prefix: str = f\"../submission/{folder_to_str}\"\n",
    "print(\"Model coding: \", folder_to_str)\n",
    "\n",
    "month_to_date = lambda x: f\"{1980 + (x - 1) // 12}-{((x - 1) % 12) + 1}-01\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287117ea9bdad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{figures_prefix}/force_plots\", exist_ok=True)\n",
    "os.makedirs(f\"{figures_prefix}/histograms\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4fb973107318c",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ada3b7f4fa1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_features = pd.read_csv(\n",
    "    f\"../data/cm_features_v{cm_features_version}_Y{prediction_year}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01f97f55f8775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load benchmark model\n",
    "model_names: dict[str, str] = {\n",
    "    \"bootstrap\": \"bm_cm_bootstrap_expanded_\",\n",
    "    \"poisson\": \"bm_cm_last_historical_poisson_expanded_\",\n",
    "    \"conflictology\": \"bm_conflictology_cm_\",\n",
    "}\n",
    "model_name: str = model_names[\"poisson\"]\n",
    "benchmark_model = pd.read_parquet(\n",
    "    f\"../benchmarks/{model_name}{prediction_year}.parquet\"\n",
    ")\n",
    "\n",
    "# Group by 'month_id' and 'country_id' and calculate mean and std for each group\n",
    "agg_funcs: dict[str, tuple[str, str]] = {\n",
    "    \"outcome\": (\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "    )  # Assuming 'prediction' is the column to aggregate; adjust if necessary\n",
    "}\n",
    "\n",
    "# there is 20 draws per each country per each month. Get the mean of the draws and std for each month\n",
    "benchmark_model = (\n",
    "    benchmark_model.groupby([\"month_id\", \"country_id\"]).agg(agg_funcs).reset_index()\n",
    ")\n",
    "\n",
    "# Flatten the multi-level columns resulting from aggregation\n",
    "benchmark_model.columns = [\n",
    "    \"_\".join(col).strip() if col[1] else col[0]\n",
    "    for col in benchmark_model.columns.values\n",
    "]\n",
    "\n",
    "# Rename columns\n",
    "benchmark_model.rename(\n",
    "    columns={\"outcome_mean\": \"outcome\", \"outcome_std\": \"outcome_std\"}, inplace=True\n",
    ")\n",
    "\n",
    "if prediction_year == 2024:\n",
    "    # SHIFT MONTHS BACK BY 7 MONTHS in benchmarks as it starts from.\n",
    "    # TODO: Check if this is valid (probably not but this is a bug in inputs)\n",
    "    # TODO: Report to PRIO\n",
    "    benchmark_model[\"month_id\"] = benchmark_model[\"month_id\"] - 6\n",
    "\n",
    "# add date column\n",
    "benchmark_model[\"date\"] = views_month_id_to_date(benchmark_model[\"month_id\"])\n",
    "print([month_to_date(month) for month in benchmark_model[\"month_id\"].unique()])\n",
    "\n",
    "# benchmark_model.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84276e0f1bcb227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load actuals\n",
    "actuals_model = pd.read_parquet(\n",
    "    f\"../actuals/cm/window=Y{prediction_year}/cm_actuals_{prediction_year}.parquet\"\n",
    ").reset_index(drop=False)\n",
    "\n",
    "# actuals_model = actuals_model.groupby(['month_id', 'country_id']).mean().reset_index()\n",
    "actuals_model[\"date\"] = views_month_id_to_date(actuals_model[\"month_id\"])\n",
    "print(actuals_model[\"month_id\"].unique())\n",
    "\n",
    "# rename outcome to ged_sb\n",
    "actuals_model.rename(columns={\"outcome\": \"ged_sb\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65a03f76a283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all columns that have ged_sb_y_ in the name\n",
    "all_targets: list[str] = [\n",
    "    col for col in cm_features.columns if col.startswith(\"ged_sb_y_\")\n",
    "]\n",
    "target: str = f\"ged_sb_{prediction_window}\"\n",
    "\n",
    "# drop all possible targets except the chosen\n",
    "try:\n",
    "    all_targets.remove(target)\n",
    "except ValueError:\n",
    "    pass\n",
    "cm_features.drop(columns=all_targets, inplace=True)\n",
    "\n",
    "# drop all rows for which ged_sb_y_15 is NAN\n",
    "cm_features = cm_features.dropna()\n",
    "\n",
    "if SHOW_PLOTS:\n",
    "    # plot target per month\n",
    "    cm_features[target].plot()\n",
    "    cm_features[\"ged_sb\"].plot()\n",
    "    cm_features[\"ged_sb_tlag_6\"].plot()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24adf390e9bebf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_features = cm_features.drop(columns=[\"country\", \"gleditsch_ward\"], errors=\"ignore\")\n",
    "# drop if exists 'year', 'ccode'\n",
    "cm_features = cm_features.drop(\n",
    "    columns=[\"year\", \"ccode\", \"region\", \"region23\"], errors=\"ignore\"\n",
    ")\n",
    "\n",
    "LEAST_IMPORTANT_FEATURES: list[str] = [\n",
    "    \"general_efficiency_t48\",\n",
    "    \"wdi_sp_dyn_imrt_in\",\n",
    "    \"vdem_v2x_egal\",\n",
    "    \"vdem_v2x_partipdem\",\n",
    "    \"vdem_v2x_partip\",\n",
    "    \"vdem_v2x_libdem\",\n",
    "    \"dam_cap_pcap_t48\",\n",
    "    \"vdem_v2xdd_dd\",\n",
    "    \"vdem_v2x_edcomp_thick\",\n",
    "    \"groundwater_export_t48\",\n",
    "    \"wdi_sh_sta_stnt_zs\",\n",
    "    \"region_Middle East & North Africa\",\n",
    "    \"vdem_v2x_execorr\",\n",
    "    \"region23_Western Asia\",\n",
    "    \"region23_Southern Europe\",\n",
    "    \"region23_Northern Africa\",\n",
    "    \"region_Sub-Saharan Africa\",\n",
    "    \"region23_Caribbean\",\n",
    "    \"region23_Eastern Europe\",\n",
    "    \"region23_Eastern Africa\",\n",
    "    \"region23_South-Eastern Asia\",\n",
    "    \"region23_Middle Africa\",\n",
    "    \"region23_Northern Europe\",\n",
    "    \"region23_Western Africa\",\n",
    "    \"region23_Southern Africa\",\n",
    "    \"region23_South America\",\n",
    "    \"region_Latin America & Caribbean\",\n",
    "    \"region23_Northern America\",\n",
    "    \"region_North America\",\n",
    "    \"region23_Melanesia\",\n",
    "    \"region23_Eastern Asia\",\n",
    "    \"region23_Central Asia\",\n",
    "    \"region23_Central America\",\n",
    "    \"region_Europe & Central Asia\",\n",
    "    \"region23_Western Europe\",\n",
    "]\n",
    "\n",
    "if DROP_35_LEAST_IMPORTANT:\n",
    "    print(\"Current number of features:\", len(cm_features.columns))\n",
    "    cm_features = cm_features.drop(columns=LEAST_IMPORTANT_FEATURES)\n",
    "    print(\n",
    "        \"Number of features after dropping 35 least important:\",\n",
    "        len(cm_features.columns),\n",
    "    )\n",
    "\n",
    "# cm_features = cm_features.drop(\n",
    "#     columns=['ged_sb_tlag_2', 'ged_sb_tlag_3', 'ged_sb_tlag_4', 'ged_sb_tlag_5', 'ged_sb_tlag_1', 'ged_sb_tlag_6', ])\n",
    "# # drop ged_sb, ged_ns, ged_os, acled_sb, acled_sb_ count, acled_os, ged_sb_tsum_24\n",
    "# cm_features = cm_features.drop(\n",
    "#     columns=['ged_sb', 'ged_ns', 'ged_os', 'acled_sb', 'acled_sb_count', 'acled_os', 'ged_sb_tsum_24', 'ged_os_tlag_1'])\n",
    "# # drop splag_1_decay_ged_sb_5, splag_1_decay_ged_os_5, splag_1_decay_ged_ns_5, decay_ged_sb_5, decay_ged_os_5, decay_ged_sb_500, decay_ged_os_100, decay_ged_ns_5, decay_ged_ns_100, decay_acled_sb_5, decay_acled_os_5, decay_acled_ns_5\n",
    "# cm_features = cm_features.drop(\n",
    "#     columns=['splag_1_decay_ged_sb_5', 'splag_1_decay_ged_os_5', 'splag_1_decay_ged_ns_5', 'decay_ged_sb_5',\n",
    "#              'decay_ged_os_5', 'decay_ged_sb_500', 'decay_ged_os_100', 'decay_ged_ns_5', 'decay_ged_ns_100',\n",
    "#              'decay_acled_sb_5', 'decay_acled_os_5', 'decay_acled_ns_5', 'decay_ged_sb_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a80f82d6fc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save first 50 rows of the dataset to a new csv file with column names\n",
    "# cm_features.head(50).to_csv('data/cm_features_first_50.csv', index=True)\n",
    "# cm_features.head(10)\n",
    "# prepare dataset for machine learning\n",
    "\n",
    "cm_features[\"date\"] = pd.to_datetime(cm_features[\"date\"])\n",
    "cm_features[\"country_id\"] = cm_features[\"country_id\"].astype(\"category\")\n",
    "\n",
    "cm_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2bedf1f3fb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode 'country_id'\n",
    "if INCLUDE_COUNTRY_ID:\n",
    "    # TODO: try what changes if encode ccode\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    encoder.fit(cm_features[[\"country_id\"]])\n",
    "    countries_encoded = encoder.transform(cm_features[[\"country_id\"]])\n",
    "\n",
    "    # rename the columns\n",
    "    countries_encoded = pd.DataFrame(\n",
    "        countries_encoded, columns=encoder.get_feature_names_out([\"country_id\"])\n",
    "    )\n",
    "    countries_encoded = countries_encoded.drop(\n",
    "        columns=\"country_id_1\"\n",
    "    )  # drop country_id_1\n",
    "    # drop na\n",
    "\n",
    "    # countries_encoded\n",
    "    # merge the encoded features with the original dataset\n",
    "    cm_features = pd.concat([cm_features, countries_encoded], axis=1)\n",
    "    cm_features = cm_features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eabfc8ef67073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TRANSFORM:\n",
    "    cm_features_original_target = cm_features[target]\n",
    "    cm_features[target] = np.log(cm_features[target] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92147e96a900a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "# prediction_year = 2018\n",
    "# test(final model evaluation): Jan 2018 - Dec 2018 (12 months)\n",
    "# Nov 2016 (Nov 2016 month_id 443)    predicts Jan 2018 (Nov 2016 443+3+11=457)\n",
    "# Oct 2017 (Nov 2016 month_id+11=454) predicts Dec 2018 (Oct 2017 454+3+11=468)\n",
    "# train_df is until Oct 2016 inclusive\n",
    "# test_df is one year from Nov 2016 to Oct 2017 inclusive\n",
    "# Note: Ideally:\n",
    "# Oct 2017 454 predicts Jan 2018 457\n",
    "# Oct 2017 454 predicts Feb 2018 458\n",
    "# ...\n",
    "# Oct 2017 454 predicts Dec 2018 468\n",
    "last_month_id: int = cm_features[\"month_id\"].max()\n",
    "\n",
    "train_features_to_oct: int = last_month_id - 11 - 3\n",
    "test_features_since_nov: int = last_month_id - 11\n",
    "\n",
    "print(\"features_to_oct:\", train_features_to_oct)\n",
    "print(\"features_since_nov:\", test_features_since_nov)\n",
    "\n",
    "train_df = cm_features[\n",
    "    cm_features[\"month_id\"] <= train_features_to_oct\n",
    "]  # train is till 476 inclusive\n",
    "\n",
    "# test_df is one year from Nov to Oct inclusive (479-490)\n",
    "test_df = cm_features[(cm_features[\"month_id\"] >= test_features_since_nov)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17003378fb525f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df['month_id'].unique())\n",
    "# print(test_df['month_id'].unique())\n",
    "# # count number of unique dates\n",
    "# print(test_df['month_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb61a09f1faada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of rows where target is 0\n",
    "# drop 0 rows from train df\n",
    "if DROP_0_ROWS_PERCENT > 0:\n",
    "    print(f\"Initial count: {train_df[train_df[target] == 0].shape[0]}\")\n",
    "\n",
    "    indices = train_df[train_df[target] == 0].index.to_series()\n",
    "\n",
    "    num_to_drop: int = int(len(indices) * DROP_0_ROWS_PERCENT / 100)\n",
    "    indices_to_drop = indices.sample(n=num_to_drop, random_state=42)\n",
    "\n",
    "    train_df = train_df.drop(indices_to_drop)\n",
    "\n",
    "    print(f\"Count after removal: {train_df[train_df[target] == 0].shape[0]}\")\n",
    "\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080be893a6dca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training set\n",
    "# train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f7867d7b786c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save date column for test_df\n",
    "test_df_date = test_df[\"date\"]\n",
    "train_df_date = train_df[\"date\"]\n",
    "\n",
    "test_df_country_name = test_df[\"gw_statename\"]\n",
    "train_df_country_name = train_df[\"gw_statename\"]\n",
    "\n",
    "train_df_country_id = train_df[\"country_id\"]\n",
    "test_df_country_id = test_df[\"country_id\"]\n",
    "\n",
    "train_df_month_id = train_df[\"month_id\"]\n",
    "test_df_month_id = test_df[\"month_id\"]\n",
    "\n",
    "test_df = test_df.drop(\"date\", axis=1)\n",
    "test_df = test_df.drop(\"country_id\", axis=1)\n",
    "test_df = test_df.drop(\"gw_statename\", axis=1)\n",
    "\n",
    "train_df = train_df.drop(\"date\", axis=1)\n",
    "train_df = train_df.drop(\"country_id\", axis=1)\n",
    "train_df = train_df.drop(\"gw_statename\", axis=1)\n",
    "\n",
    "# if CREATE_VAL_DS:\n",
    "#     val_df_date = validation_df['date']\n",
    "#     val_df_country_id = validation_df['country_id']\n",
    "#     val_df_month_id = validation_df['month_id']\n",
    "#     validation_df = validation_df.drop('date', axis=1)\n",
    "#     validation_df = validation_df.drop(\"country_id\", axis=1)\n",
    "#     validation_df = validation_df.drop(\"gw_statename\", axis=1)\n",
    "\n",
    "if not INCLUDE_MONTH_ID:\n",
    "    test_df = test_df.drop(\"month_id\", axis=1)\n",
    "    train_df = train_df.drop(\"month_id\", axis=1)\n",
    "    # if CREATE_VAL_DS:\n",
    "    #     validation_df = validation_df.drop('month_id', axis=1)\n",
    "\n",
    "print(test_df_month_id.unique())\n",
    "\n",
    "print(\"Difference between benchmark and test month_id:\")\n",
    "print(benchmark_model[\"month_id\"].min() - test_df_month_id.max())\n",
    "print(benchmark_model[\"month_id\"].min() - test_df_month_id.min())\n",
    "# train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6342ef23bbbf8",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ac1dfcb2a2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(target, axis=1)\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_test = test_df.drop(target, axis=1)\n",
    "y_test = test_df[target]\n",
    "\n",
    "# if CREATE_VAL_DS:\n",
    "#     X_val = validation_df.drop(target, axis=1)\n",
    "#     y_val = validation_df[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13287fc543e63708",
   "metadata": {},
   "source": [
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce8ab24c127afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# Model tuning:\n",
    "model_files = list(Path(model_cache_prefix).glob(\"model_*.p\"))\n",
    "\n",
    "cached_model_available = len(model_files) > 0\n",
    "print(\"Cached model available:\", cached_model_available)\n",
    "\n",
    "if USE_CACHED_MODEL and cached_model_available:\n",
    "    model_path = model_files[0]\n",
    "\n",
    "    with model_path.open(\"rb\") as file:\n",
    "        ngb = pickle.load(file)\n",
    "else:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        print(f\"Training NGB with {n_estimators} estimators and {score} score...\")\n",
    "        ngb = NGBRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            verbose_eval=10,\n",
    "            Dist=dist,\n",
    "            learning_rate=0.01,\n",
    "            Score=score,\n",
    "            random_state=42,\n",
    "            Base=base_learner,\n",
    "            minibatch_frac=minibatch_frac,\n",
    "            # col_sample=1.0,\n",
    "        ).fit(\n",
    "            X_train, y_train, X_test, y_test\n",
    "        )  # be careful with this, not to use early stopping\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    for file_path in model_files:\n",
    "        file_path.unlink()\n",
    "    Path(model_cache_prefix).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    time = datetime.now()\n",
    "\n",
    "    model = (\n",
    "        \"model_\" f\"{time.day}_{time.month}_{time.year}_\" f\"{time.hour}_{time.minute:02}\"\n",
    "    )\n",
    "\n",
    "    with Path(model_cache_prefix, model).with_suffix(\".p\").open(\"wb\") as file:\n",
    "        pickle.dump(ngb, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9ba6ad9bd0b1",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4c112d5b873d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_train_predictions = ngb.predict(X_train)\n",
    "ngb_predictions = ngb.predict(X_test)\n",
    "ngb_predictions_dist = ngb.pred_dist(X_test)\n",
    "# means and stds of the predictions\n",
    "# mean, std = ngb_predictions_dist.loc, ngb_predictions_dist.scale\n",
    "\n",
    "if not LOG_TRANSFORM:\n",
    "    ngb_train_predictions = [max(0, pred) for pred in ngb_train_predictions]\n",
    "    ngb_predictions = [max(0, pred) for pred in ngb_predictions]\n",
    "\n",
    "sampled_dist = ngb_predictions_dist.sample(1000).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534ca6a78ba90",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad65d78b2003b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_CRPS(sampled_dist, y_true, index_start, index_end):\n",
    "    scores: list[float] = []\n",
    "\n",
    "    for indx, y_point in enumerate(y_true[index_start:index_end]):\n",
    "        crps_score: float = pscore(sampled_dist[indx], y_point).compute()[0]\n",
    "        scores.append(crps_score)\n",
    "\n",
    "    return np.average(scores)\n",
    "\n",
    "\n",
    "# average crps score\n",
    "\n",
    "print(f\"Average CRPS score: {calculate_CRPS(sampled_dist, y_test, 0, len(y_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8692554719dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map predictions to months based on the test_df\n",
    "test_df[\"ngb_predictions\"] = ngb_predictions\n",
    "train_df[\"ngb_predictions\"] = ngb_train_predictions\n",
    "\n",
    "# add date column back to test_df and add to each date shift of 14 months\n",
    "test_df[\"date\"] = test_df_date + pd.DateOffset(months=prediction_window)\n",
    "train_df[\"date\"] = train_df_date\n",
    "\n",
    "test_df[\"country_id\"] = test_df_country_id\n",
    "train_df[\"country_id\"] = train_df_country_id\n",
    "\n",
    "test_df[\"month_id\"] = test_df_month_id\n",
    "train_df[\"month_id\"] = train_df_month_id\n",
    "\n",
    "test_df[\"country_name\"] = test_df_country_name\n",
    "train_df[\"country_name\"] = train_df_country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0a83d44e08ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Improve metrics and use all metrics from the VIEWS competition\n",
    "# Calculate RMSE\n",
    "# train_rmse = sqrt(mean_squared_error(y_train, xg_lss_pred_train))\n",
    "# actuals_rmse = sqrt(mean_squared_error(actuals_model['ged_sb'], predictions))\n",
    "# benchmark_rmse = sqrt(mean_squared_error(y_test, benchmark_model['outcome']))\n",
    "ngb_train_rmse = sqrt(mean_squared_error(y_train, ngb_train_predictions))\n",
    "ngb_test_rmse = sqrt(mean_squared_error(y_test, ngb_predictions))\n",
    "all_zeros_rmse = sqrt(mean_squared_error(y_test, [0] * len(y_test)))\n",
    "# added if cases because length need to be equal, and if year is not full,\n",
    "# then we need to make benchmark_model['outcome'] and actuals_model['ged_sb']\n",
    "\n",
    "if prediction_year == 2024:\n",
    "    actuals_length = len(actuals_model[\"ged_sb\"])\n",
    "    actuals_bench_rmse = sqrt(\n",
    "        mean_squared_error(\n",
    "            actuals_model[\"ged_sb\"], benchmark_model[\"outcome\"][:actuals_length]\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    actuals_bench_rmse = sqrt(\n",
    "        mean_squared_error(actuals_model[\"ged_sb\"], benchmark_model[\"outcome\"])\n",
    "    )\n",
    "\n",
    "print(\"Cm features version:\", cm_features_version)\n",
    "print(f\"Prediction year: {prediction_year}\")\n",
    "print(f\"Include country_id: {INCLUDE_COUNTRY_ID}\")\n",
    "print(f\"Include month_id: {INCLUDE_MONTH_ID}\")\n",
    "print(f\"Drop train 0 rows: {DROP_0_ROWS_PERCENT}%\")\n",
    "print(f\"Normal distribution: {dist == Normal}\")\n",
    "print(f\"Number of estimators: {n_estimators}\")\n",
    "print(f\"Score: {str(score.__name__)}\")\n",
    "print(f\"Log transform: {LOG_TRANSFORM}\")\n",
    "print(f\"Base learner max depth: {bs_max_depth}\")\n",
    "print(f\"Minibatch fraction: {minibatch_frac}\")\n",
    "\n",
    "# print(f\"XGB [train predictions] RMSE: {train_rmse}\")\n",
    "# print(f\"XGB [test predictions]  RMSE YTEST VS PREDICTIONS: {rmse}\")\n",
    "print(f\"\\nNGB [train predictions] RMSE NGB: {ngb_train_rmse}\")\n",
    "print(f\"NGB [test predictions]  RMSE NGB: {ngb_test_rmse}\")\n",
    "# if CREATE_VAL_DS:\n",
    "#     ngb_val_rmse = sqrt(mean_squared_error(y_val, ngb.predict(X_val)))\n",
    "#     print(f\"NGB [validation predictions] RMSE NGB: {ngb_val_rmse}\")\n",
    "\n",
    "# print(f\"RMSE YTEST VS ACTUALS: {actuals_rmse}')\n",
    "# print(f\"RMSE YTEST VS BENCHMARK: {benchmark_rmse}')\n",
    "print(f\"All Zeros: {all_zeros_rmse}\")\n",
    "print(f\"\\nBenchmark: RMSE ACTUALS VS BENCHMARK: {actuals_bench_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393ec17c5a13ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TRANSFORM:\n",
    "    test_df[\"original_\" + target] = cm_features_original_target\n",
    "    test_df[\"ngb_predictions_inverselog_std\"] = (np.exp(sampled_dist) - 1).std(axis=1)\n",
    "    test_df[\"ngb_predictions_inverselog\"] = np.exp(test_df[\"ngb_predictions\"]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41852663755b1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_STD:\n",
    "    # dir(ngb.pred_dist(X_test).scale)\n",
    "    # ngb.pred_dist(X_test).\n",
    "    # save std of the predictions\n",
    "    # TODO: Keep only sampled and remove normal_enabled condition\n",
    "\n",
    "    ngb_predictions_std = sampled_dist.std(axis=1)\n",
    "    ngb_predictions_std_ = np.sqrt(ngb_predictions_dist.var)\n",
    "\n",
    "    confidence: float = 0.10\n",
    "    if not (\n",
    "        sum(ngb_predictions_std <= ngb_predictions_std_ * (1 - confidence))\n",
    "    ) and not (sum(ngb_predictions_std >= ngb_predictions_std_ * (1 + confidence))):\n",
    "        print(f\"Confidence: +-{confidence:.0%}\")\n",
    "    # ngb_predictions_std_[0] # float\n",
    "    # if dist == Normal:\n",
    "    #     ngb_predictions_std = np.sqrt(ngb_predictions_dist.var)\n",
    "    # else:\n",
    "    #     # sampled_dist = ngb_predictions_dist.sample(1000)\n",
    "    #\n",
    "    #     ngb_predictions_max = sampled_dist.max(axis=0)\n",
    "    #     ngb_predictions_min = sampled_dist.min(axis=0)\n",
    "    #\n",
    "    #     test_df['ngb_predictions_max'] = ngb_predictions_max\n",
    "    #     test_df['ngb_predictions_min'] = ngb_predictions_min\n",
    "\n",
    "    # add std to test_df\n",
    "    test_df[\"ngb_predictions_std\"] = ngb_predictions_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51e1de19a324b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = test_df\n",
    "# temp.reset_index(inplace=False, drop=False)\n",
    "#\n",
    "# # get row with the highest number of deaths\n",
    "# temp[temp['predictions'] == temp['predictions'].max()]\n",
    "# print(temp[temp['predictions'] == temp['predictions'].min()])\n",
    "\n",
    "cutoff_date = actuals_model[\"date\"].iloc[-1].date().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "if prediction_year == 2024:\n",
    "    cutoff_date = pd.to_datetime(f\"{cutoff_date}\")\n",
    "\n",
    "else:\n",
    "    cutoff_date = pd.to_datetime(f\"{prediction_year}-12-01\")\n",
    "\n",
    "# NOTE !!!!\n",
    "# test_df.reset_index(inplace=True, drop=True)\n",
    "ngb_predictions_sampled = ngb_predictions_dist.sample(1000).T.astype(int)\n",
    "test_df_edge = test_df.shape[1]\n",
    "test_df_new = pd.concat([test_df, pd.DataFrame(ngb_predictions_sampled)], axis=1)\n",
    "\n",
    "ngb_predictions_sampled[12] == test_df_new.iloc[12, test_df_edge:]\n",
    "\n",
    "# get the row with the highest number of deaths\n",
    "# actuals_model\n",
    "\n",
    "\n",
    "# add to test_df_new the actuals based on month_id and country_id\n",
    "# actuals_model.rename(columns={'ged_sb': 'actuals'}, inplace=True)\n",
    "# test_df_new.merge(actuals_model[['month_id', 'country_id', 'actuals']], on=['month_id', 'country_id'])\n",
    "\n",
    "# drop level 0 and index columns\n",
    "# test_df.drop(columns=['level_0', 'index'], inplace=True, errors='ignore')# test_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2054063c3472477",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_PREDICTIONS:\n",
    "    # Save predictions\n",
    "    # TODO: for countries that are in actuals but not in the predictions, add them to the predictions with 0\n",
    "    #  test_df['country_id'].unique()\n",
    "    #  actuals_model['country_id'].unique()\n",
    "    missing_countries = set(benchmark_model[\"country_id\"].unique()) - set(\n",
    "        test_df_new[\"country_id\"].unique()\n",
    "    )\n",
    "\n",
    "    # save predictions to a csv file\n",
    "    # for each month for each country create 20 draws of the prediction named outcome\n",
    "    # the structure of the file should be month_id, country_id, draw, outcome\n",
    "    new_predictions_list = []\n",
    "    all_countries = set(test_df_new[\"country_id\"].unique()).union(missing_countries)\n",
    "\n",
    "    for month_id in test_df_new[\"month_id\"].unique():\n",
    "        for country_id in all_countries:\n",
    "            this_country_month = test_df_new[\n",
    "                (test_df_new[\"month_id\"] == month_id)\n",
    "                & (test_df_new[\"country_id\"] == country_id)\n",
    "            ]\n",
    "\n",
    "            if country_id in missing_countries:\n",
    "                outcomes = np.zeros(1000)\n",
    "            else:\n",
    "                outcomes = this_country_month.iloc[:, test_df_edge:].values[0]\n",
    "\n",
    "                if LOG_TRANSFORM:\n",
    "                    outcomes = np.exp(outcomes) - 1\n",
    "\n",
    "                # remove all values smaller than 0\n",
    "                non_negatives = outcomes[outcomes >= 0]\n",
    "                negative_counts = np.sum(outcomes < 0)\n",
    "\n",
    "                if negative_counts > 0:\n",
    "                    # Sample from the non-negative distribution to replace negative values\n",
    "                    # We assume the distribution of non-negatives is suitable for sampling\n",
    "                    sampled_values = np.random.choice(\n",
    "                        non_negatives, size=negative_counts\n",
    "                    )\n",
    "                    outcomes[outcomes < 0] = sampled_values\n",
    "\n",
    "                assert all(\n",
    "                    outcomes >= 0\n",
    "                ), \"There are still negative values in the outcomes\"\n",
    "\n",
    "            new_predictions_list.extend(\n",
    "                [\n",
    "                    {\n",
    "                        \"month_id\": month_id\n",
    "                        + prediction_window,  # adjust for prediction window\n",
    "                        \"country_id\": country_id,\n",
    "                        \"draw\": draw,\n",
    "                        \"outcome\": outcome,\n",
    "                    }\n",
    "                    for draw, outcome in enumerate(outcomes, start=0)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    # set month_id, country_id, draw as int and outcome as float\n",
    "    new_predictions = pd.DataFrame(new_predictions_list)\n",
    "\n",
    "    new_predictions[\"month_id\"] = new_predictions[\"month_id\"].astype(int)\n",
    "    new_predictions[\"country_id\"] = new_predictions[\"country_id\"].astype(int)\n",
    "    new_predictions[\"draw\"] = new_predictions[\"draw\"].astype(int)\n",
    "    new_predictions[\"outcome\"] = new_predictions[\"outcome\"].astype(int)\n",
    "\n",
    "    # set index to month_id, country_id, draw\n",
    "    new_predictions.set_index([\"month_id\", \"country_id\", \"draw\"], inplace=True)\n",
    "\n",
    "    # create folder if it does not exist recursively\n",
    "\n",
    "    folder = f\"{submission_prefix}/cm/window=Y{prediction_year}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    new_predictions.to_parquet(folder + f\"/submission_Y{prediction_year}.parquet\")\n",
    "\n",
    "    print(f\"Predictions saved\")\n",
    "    print(f\"Saved to {folder}\")\n",
    "else:\n",
    "    print(\"Predictions not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032c295bc461b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "country_list = pd.read_csv(\"../data/country_list.csv\")\n",
    "country_ids = test_df[\"country_id\"].unique().tolist()\n",
    "\n",
    "# Settings\n",
    "num_plots_per_figure = 4\n",
    "plt.figure(figsize=(15, 10))  # New figure\n",
    "plots_added = 0\n",
    "\n",
    "# Continue looping until all countries have been considered\n",
    "max_date_train = pd.to_datetime(train_df[\"date\"].max())\n",
    "min_date_test = pd.to_datetime(test_df[\"date\"].min())\n",
    "\n",
    "# 1 year buffer because of validation set\n",
    "expected_min_date_test = max_date_train + relativedelta(\n",
    "    years=0, months=prediction_window + 3\n",
    ")  # 15 is window size + 1 is from Sep to Oct\n",
    "\n",
    "print(f\"Max date in training set: {max_date_train}\")\n",
    "print(f\"Min date in test set: {min_date_test}\")\n",
    "print(f\"Expected min date in test set: {expected_min_date_test}\")\n",
    "\n",
    "# assert the different is exactly 15 months\n",
    "assert min_date_test == expected_min_date_test\n",
    "\n",
    "for index, country_id in enumerate(country_ids):\n",
    "    # Ensure we output actual values only till they exist for 2024 edge case\n",
    "\n",
    "    this_country_test = test_df[test_df[\"country_id\"] == country_id]\n",
    "    this_country_train = train_df[train_df[\"country_id\"] == country_id]\n",
    "    this_country_train = this_country_train.tail(24)\n",
    "    if LOG_TRANSFORM:\n",
    "        this_country_target = this_country_test[\"original_\" + target][\n",
    "            this_country_test[\"date\"] <= cutoff_date\n",
    "        ]\n",
    "    else:\n",
    "        this_country_target = this_country_test[target][\n",
    "            this_country_test[\"date\"] <= cutoff_date\n",
    "        ]\n",
    "\n",
    "    predictions_vector = (\n",
    "        this_country_test[\"ngb_predictions\"]\n",
    "        if not LOG_TRANSFORM\n",
    "        else this_country_test[\"ngb_predictions_inverselog\"]\n",
    "    )\n",
    "    std_vector = (\n",
    "        this_country_test[\"ngb_predictions_std\"]\n",
    "        if not LOG_TRANSFORM\n",
    "        else this_country_test[\"ngb_predictions_inverselog_std\"]\n",
    "    )\n",
    "\n",
    "    country_name = country_list[country_list[\"country_id\"] == country_id][\n",
    "        \"name\"\n",
    "    ].values[0]\n",
    "\n",
    "    # Check if country should be skipped because it is not interesting\n",
    "    if this_country_target.sum() == 0:\n",
    "        if SHOW_PLOTS:\n",
    "            print(f\"Skipping {country_name} as all actual are 0\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the subplot for non-skipped countries\n",
    "    plt.subplot(2, 2, plots_added + 1)\n",
    "\n",
    "    # Plotting data\n",
    "    plt.plot(\n",
    "        this_country_train[\"date\"],\n",
    "        this_country_train[\"ged_sb\"],\n",
    "        label=\"Train\",\n",
    "        color=\"gray\",\n",
    "        linestyle=\"-\",\n",
    "        marker=\"\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        this_country_test[\"date\"].apply(lambda x: x - relativedelta(months=14)),\n",
    "        this_country_test[\"ged_sb\"],\n",
    "        label=f\"Test Input\",\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        marker=\"\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        this_country_test[\"date\"][this_country_test[\"date\"] <= cutoff_date],\n",
    "        this_country_target,\n",
    "        label=\"Actual\",\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        marker=\"\",\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        this_country_test[\"date\"],\n",
    "        predictions_vector,\n",
    "        label=f\"Model Output\",\n",
    "        color=\"blue\",\n",
    "        linestyle=\"-\",\n",
    "        marker=\"\",\n",
    "    )\n",
    "    # plot std\n",
    "    if PLOT_STD:\n",
    "        plt.fill_between(\n",
    "            this_country_test[\"date\"],\n",
    "            predictions_vector - std_vector,\n",
    "            predictions_vector + std_vector,\n",
    "            color=\"blue\",\n",
    "            alpha=0.2,\n",
    "        )\n",
    "\n",
    "    # Adding title and labels\n",
    "    plt.title(f\"{country_name} Actual vs Predicted\")\n",
    "    plt.xlabel(\"Date\")\n",
    "\n",
    "    # turn dates 90 degrees\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # make ticks more readable\n",
    "    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter(\"%Y-%m\"))\n",
    "\n",
    "    # add vertical lines for the training and testing split\n",
    "    plt.axvline(x=min_date_test, color=\"gray\", linestyle=\"--\", label=\"16 months gap\")\n",
    "    plt.axvline(x=max_date_train, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "    plt.ylabel(\"Number of fatalities\")\n",
    "    plt.legend()\n",
    "\n",
    "    # add light grid\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Increment counters\n",
    "    plots_added += 1\n",
    "\n",
    "    if plots_added % num_plots_per_figure == 0 or index == len(country_ids) - 1:\n",
    "        # Adjust layout and display the figure\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if SHOW_PLOTS:\n",
    "            plt.show()\n",
    "\n",
    "        plt.figure(figsize=(15, 10))  # New figure\n",
    "        plots_added = 0\n",
    "\n",
    "if SHOW_PLOTS:\n",
    "    plt.show()\n",
    "\n",
    "if not SHOW_PLOTS:\n",
    "    plt.close(\"all\")\n",
    "\n",
    "this_country_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d06dc4e3dcff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if prediction_year == 2024:\n",
    "    month_to_cut = 4\n",
    "    test_df = test_df[test_df[\"date\"] <= f\"2024-{month_to_cut}-01\"]\n",
    "    test_df_new = test_df_new[test_df_new[\"date\"] <= f\"2024-{month_to_cut}-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c91b9c638dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_df is your DataFrame, and 'target' and 'predictions' are columns in it\n",
    "unique_months = test_df[\"month_id\"].unique()\n",
    "print(\"Unique months:\", unique_months)\n",
    "\n",
    "# filter all point with actual more than 300\n",
    "# test_df = test_df[test_df[target] < 300]\n",
    "\n",
    "# Calculate the grid size for the subplot (simple square root approximation for a square grid)\n",
    "n_unique_months: int = len(unique_months)\n",
    "\n",
    "grid_size_x = int(n_unique_months**0.5) + (\n",
    "    1 if n_unique_months % int(n_unique_months**0.5) else 0\n",
    ")\n",
    "grid_size_y = grid_size_x + 1\n",
    "\n",
    "# print(f'Grid size: {grid_size}')\n",
    "\n",
    "# Set overall figure size\n",
    "plt.figure(figsize=(grid_size_x * 6, grid_size_y * 3))\n",
    "\n",
    "for index, month_id in enumerate(unique_months, start=1):\n",
    "    this_month = test_df[test_df[\"month_id\"] == month_id]\n",
    "\n",
    "    # mean_sq_error = sqrt(mean_squared_error(this_month[target], this_month['ngb_predictions']))\n",
    "    current_date = this_month[\"date\"].iloc[0]\n",
    "    target_month = this_month[target]\n",
    "    predictions_month = this_month[\"ngb_predictions\"]\n",
    "\n",
    "    # get this month max and min index\n",
    "    month_start_index = this_month.index.min()\n",
    "    month_end_index = this_month.index.max()\n",
    "    mean_crps = calculate_CRPS(sampled_dist, y_test, month_start_index, month_end_index)\n",
    "\n",
    "    # Create subplot for current month\n",
    "    plt.subplot(grid_size_x, grid_size_y, index)\n",
    "    plt.scatter(\n",
    "        target_month,\n",
    "        predictions_month,\n",
    "        color=\"blue\",\n",
    "        label=\"Actual vs Predicted\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    if PLOT_STD:\n",
    "        predictions_std_month = this_month[\"ngb_predictions_std\"]\n",
    "        plt.errorbar(\n",
    "            target_month,\n",
    "            predictions_month,\n",
    "            yerr=predictions_std_month,\n",
    "            fmt=\"o\",\n",
    "            color=\"blue\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "    # print current_date in YY/MM format\n",
    "    print_date = current_date.strftime(\"%Y-%m\")\n",
    "\n",
    "    plt.title(f\"Month: {print_date}; mean CRPS: {mean_crps:.2f}\", fontsize=11)\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "\n",
    "    # plt.xscale('log')\n",
    "    # plt.yscale('log')\n",
    "\n",
    "    if not LOG_TRANSFORM:\n",
    "        line_length = 2000  # default\n",
    "    else:\n",
    "        line_length = 8  # for log transformed\n",
    "\n",
    "    plt.plot([0, line_length], [0, line_length], color=\"red\", label=\"45 degree line\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# set font size to fit better\n",
    "plt.rcParams.update({\"font.size\": 9 if LOG_TRANSFORM else 10})\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(f\"{figures_prefix}/NGBoost_predictions.png\", dpi=300)\n",
    "\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1830c181161e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TRANSFORM:\n",
    "    # Set overall figure size\n",
    "    plt.figure(figsize=(grid_size_x * 6, grid_size_y * 3))\n",
    "\n",
    "    for index, month_id in enumerate(unique_months, start=1):\n",
    "        this_month = test_df[test_df[\"month_id\"] == month_id]\n",
    "\n",
    "        # mean_sq_error = sqrt(mean_squared_error(this_month[target], this_month['ngb_predictions']))\n",
    "        current_date = this_month[\"date\"].iloc[0]\n",
    "        target_month = np.exp(this_month[target]) - 1\n",
    "        predictions_month = np.exp(this_month[\"ngb_predictions\"]) - 1\n",
    "\n",
    "        # get this month max and min index\n",
    "        month_start_index = this_month.index.min()\n",
    "        month_end_index = this_month.index.max()\n",
    "        mean_crps = calculate_CRPS(\n",
    "            np.exp(sampled_dist) - 1,\n",
    "            np.exp(y_test) - 1,\n",
    "            month_start_index,\n",
    "            month_end_index,\n",
    "        )\n",
    "\n",
    "        # Create subplot for current month\n",
    "        plt.subplot(grid_size_x, grid_size_y, index)\n",
    "        plt.scatter(\n",
    "            target_month,\n",
    "            predictions_month,\n",
    "            color=\"blue\",\n",
    "            label=\"Actual vs Predicted\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "        if PLOT_STD:\n",
    "            predictions_std_month = this_month[\"ngb_predictions_inverselog_std\"]\n",
    "            plt.errorbar(\n",
    "                target_month,\n",
    "                predictions_month,\n",
    "                yerr=predictions_std_month,\n",
    "                fmt=\"o\",\n",
    "                color=\"blue\",\n",
    "                alpha=0.5,\n",
    "            )\n",
    "\n",
    "        # print current_date in YY/MM format\n",
    "        print_date = current_date.strftime(\"%Y-%m\")\n",
    "\n",
    "        plt.title(f\"Month: {print_date}; mean CRPS: {mean_crps:.2f}\")\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "\n",
    "        # plt.xscale('log')\n",
    "        # plt.yscale('log')\n",
    "\n",
    "        line_length = 2000\n",
    "        plt.plot(\n",
    "            [0, line_length], [0, line_length], color=\"red\", label=\"45 degree line\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # set font size to 18\n",
    "    plt.rcParams.update({\"font.size\": 10})\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(f\"{figures_prefix}/NGBoost_predictions_inverselog.png\", dpi=300)\n",
    "\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c1f15483506e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_PLOTS or SAVE_FIGURES:\n",
    "    plt.close(\"all\")\n",
    "    shap.initjs()\n",
    "    explainer = shap.TreeExplainer(\n",
    "        ngb, model_output=0\n",
    "    )  # use model_output = 1 for scale trees\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    shap.summary_plot(\n",
    "        shap_values, X_test, feature_names=X_test.columns, show=False, max_display=10\n",
    "    )\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(f\"{figures_prefix}/NGBoost_shap_values.png\", dpi=300)\n",
    "\n",
    "    if SHOW_PLOTS:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3540cf4642adff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHAP plot for loc trees\n",
    "feature_importance_loc = ngb.feature_importances_[0]\n",
    "feature_importance_loc = pd.DataFrame(\n",
    "    feature_importance_loc, index=X_train.columns, columns=[\"importance\"]\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "feature_importance_scale = ngb.feature_importances_[1]\n",
    "feature_importance_scale = pd.DataFrame(\n",
    "    feature_importance_scale, index=X_train.columns, columns=[\"importance\"]\n",
    ").sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# save as list names of 35 least important features\n",
    "# feature_importance_loc.tail(35).index.tolist()\n",
    "feature_importance_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05650f80be68d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter Ethiopia\n",
    "\n",
    "# ethiopia_test = test_df[test_df['country_id'] == 57]\n",
    "# ethiopia_test_max_error_index = test_df['ngb_predictions'].idxmax()\n",
    "# X_test.iloc[ethiopia_test_max_error_index][[target]]\n",
    "# X_test[ethiopia_test_max_error_index:ethiopia_test_max_error_index + 1]\n",
    "# test_df['ngb_predictions'].idxmax()\n",
    "# print country name\n",
    "if SHOW_PLOTS:\n",
    "    print(test_df.iloc[test_df[\"ngb_predictions\"].idxmax()][\"country_name\"])\n",
    "    shap.plots.force(\n",
    "        explainer.expected_value,\n",
    "        shap_values[test_df[\"ngb_predictions\"].idxmax()],\n",
    "        X_test.iloc[test_df[\"ngb_predictions\"].idxmax()],\n",
    "        matplotlib=True,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f38178bf62e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a force plot for a separate prediction\n",
    "countries_to_force_plot: list[str] = [\"Ethiopia\", \"Turkey\", \"Algeria\"]\n",
    "\n",
    "for country_name in countries_to_force_plot:\n",
    "    indexes_for_country = test_df[\n",
    "        test_df[\"country_name\"].str.contains(country_name)\n",
    "    ].index\n",
    "\n",
    "    for m, index in enumerate(indexes_for_country, start=1):\n",
    "        shap.force_plot(\n",
    "            explainer.expected_value,\n",
    "            shap_values[index],\n",
    "            X_test.iloc[index],\n",
    "            matplotlib=True,\n",
    "            show=False,\n",
    "        )\n",
    "        # add vectical of true value\n",
    "        # plt.axvline(x=y_test.iloc[index], color='red', linestyle='--')\n",
    "        plt.legend([f\"Actual: {y_test.iloc[index]}\"], loc=\"upper left\")\n",
    "\n",
    "        if SHOW_PLOTS:\n",
    "            plt.show()\n",
    "\n",
    "        if SAVE_FIGURES:\n",
    "            plt.savefig(\n",
    "                f\"{figures_prefix}/force_plots/NGBoost_shap_fp_{country_name}_{m}_{index}.png\",\n",
    "                dpi=300,\n",
    "            )\n",
    "\n",
    "if not SHOW_PLOTS:\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1a01dd564160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stanfordmlgroup.github.io/ngboost/3-interpretation.html\n",
    "# DO_IMPORTANCE = False\n",
    "# # print all feature importance sorted\n",
    "# feature_importance = bst.get_fscore()\n",
    "# feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(feature_importance)\n",
    "#\n",
    "# if DO_IMPORTANCE:\n",
    "#     from xgboost import plot_importance\n",
    "#\n",
    "#     # plot\n",
    "#     plot_importance(bst, max_num_features=10)\n",
    "#     plt.show()\n",
    "#\n",
    "#     import shap\n",
    "#\n",
    "#     explainer = shap.TreeExplainer(bst)\n",
    "#     # dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "#     dtrain.feature_names = X_train.columns.tolist()\n",
    "#     explanation = explainer(dtrain)\n",
    "#     explanation = shap.Explanation(\n",
    "#         values=explanation.values,\n",
    "#         base_values=explanation.base_values,\n",
    "#         data=explanation.data,\n",
    "#         feature_names=X_train.columns.tolist()\n",
    "#     )\n",
    "#     shap.plots.beeswarm(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063b6b0da33f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len((np.exp(sampled_dist) - 1).std(axis=0))\n",
    "# len(sampled_dist.std(axis=1))\n",
    "#\n",
    "# (np.exp(sampled_dist.std(axis=1)) - 1).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2819b923d79f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get observations with the highest error\n",
    "# calculate the error\n",
    "test_df[\"error\"] = abs(test_df[target] - test_df[\"ngb_predictions\"])\n",
    "\n",
    "temp_df = test_df.sort_values(by=\"error\", ascending=False)\n",
    "highest_error_indices = temp_df.head(10).index\n",
    "del temp_df\n",
    "# highest_error_indices\n",
    "\n",
    "# get the highest error\n",
    "highest_error = test_df.nlargest(30, \"error\")\n",
    "\n",
    "# drop columns that contain 'country_id_'\n",
    "highest_error = highest_error[\n",
    "    highest_error.columns.drop(list(highest_error.filter(regex=\"country_id_\")))\n",
    "]\n",
    "\n",
    "# add country name\n",
    "country_list = pd.read_csv(\"../data/country_list.csv\")\n",
    "\n",
    "highest_error = highest_error.merge(country_list, on=\"country_id\")\n",
    "highest_error\n",
    "# from the test_df get sorted by highest, get the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e8a243be5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean error for Ethiopia\n",
    "ethiopia_error = test_df[test_df[\"country_id\"] == 57]\n",
    "ethiopia_error[\"error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7fe8201f0d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_predictions_sampled = ngb_predictions_dist.sample(1000).T.astype(int)\n",
    "#\n",
    "# concat to test_df\n",
    "# test_df = pd.concat([test_df, ngb_predictions_sampled], axis=1)\n",
    "\n",
    "\n",
    "# negative_mask = ngb_predictions_sampled < 0\n",
    "# # print how many negative values are there\n",
    "# print(negative_mask.sum().sum()) # 917442\n",
    "# # print total number of values\n",
    "# print(negative_mask.size) # 2028000\n",
    "# # print percentage of negative values\n",
    "# print(negative_mask.sum().sum() / negative_mask.size) #0.452387573964497\n",
    "# # sample once more and fill in the previous negative values with values from new distribution\n",
    "# ngb_predictions_sampled[negative_mask] = ngb_predictions_dist.sample(1000).T[negative_mask]\n",
    "# # print again how many negative values are there\n",
    "# negative_mask =  ngb_predictions_sampled < 0\n",
    "# print(negative_mask.sum().sum())  # 423012\n",
    "\n",
    "# # set 0 if negative\n",
    "# # ngb_predictions_sampled = ngb_predictions_sampled.clip(min=0)\n",
    "# ngb_predictions_sampled = ngb_predictions_sampled\n",
    "#\n",
    "#\n",
    "# # plot histogram of the sampled predictions using plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(\n",
    "    ngb_predictions_sampled[325], bins=50, alpha=0.7, label=\"NGB Predictions\"\n",
    ")  # MAX\n",
    "# plot a dot for the actual value\n",
    "# plt.scatter([actuals_model['ged_sb'].max()], [0], color='red', label='Actual Value')\n",
    "# plt.hist(ngb_predictions_sampled[20], bins=50, alpha=0.7, label='NGB Predictions') # MIN\n",
    "plt.title(\"Histogram of NGB Predictions\")\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "if SHOW_PLOTS:\n",
    "    plt.show()\n",
    "\n",
    "if not SHOW_PLOTS:\n",
    "    plt.close(\"all\")\n",
    "\n",
    "# ngb_predictions_sampled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff59a43f033754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(benchmark_model['country_id'].unique()) - set(test_df['country_id'].unique()))\n",
    "print(benchmark_model[\"month_id\"].unique())\n",
    "print(test_df[\"month_id\"].unique())\n",
    "print(\"Adjusted month_id for predictions:\", test_df[\"month_id\"].unique() + 15)\n",
    "set(benchmark_model[\"month_id\"].unique()) == set(test_df[\"month_id\"].unique() + 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6d441735e5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267201f0aab704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actuals_model.rename(columns={'ged_sb': 'actuals'}, inplace=True)\n",
    "# actuals_model.set_index(['month_id', 'country_id'], inplace=True)\n",
    "# test_df_new.set_index(['month_id', 'country_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174579b8d0291b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actuals_model.rename(columns={'ged_sb': 'actuals'}, inplace=True)\n",
    "# test_df_new.reset_index(inplace=True, drop=True)\n",
    "# actuals_model.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# drop actuals if it exists\n",
    "# test_df_new = test_df_new.drop(columns='actuals', errors='ignore')\n",
    "\n",
    "# join actuals to test_df_new\n",
    "# test_df_new = test_df_new.join(actuals_model['actuals'], how='left')\n",
    "# test_df_new.reset_index(inplace=True)\n",
    "# actuals_model.reset_index(inplace=True)\n",
    "# test_df_new\n",
    "# actuals_model['actuals']\n",
    "# test_df_new.head(10)\n",
    "# test_df_new.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a30d98ceb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(test_df_new.columns).index(target))\n",
    "print(len(test_df_new.columns))\n",
    "print(test_df_edge)\n",
    "\n",
    "test_df_new.head(100)[[\"month_id\", \"country_id\", target, \"ngb_predictions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad133c890b671f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df_edge = test_df_new.shape[1]\n",
    "# test_df_new = pd.concat([test_df_new, pd.DataFrame(ngb_predictions_sampled)], axis=1)\n",
    "# ngb_predictions_sampled[1] == test_df_new.iloc[1, test_df_edge:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1365706c69bcaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get id of test_df_new[target].max()\n",
    "indices_to_plot = [test_df_new[target].idxmax(), test_df_new[target].idxmin()]\n",
    "\n",
    "# add Pakistan 2020-07 or 2024-04 if prediction year is 2024\n",
    "indices_to_plot.append(\n",
    "    test_df_new[\n",
    "        (test_df_new[\"country_name\"] == \"Pakistan\")\n",
    "        & (\n",
    "            test_df_new[\"date\"]\n",
    "            == f\"{prediction_year}-0{4 if prediction_year == 2024 else 7}\"\n",
    "        )\n",
    "    ].index[0]\n",
    ")\n",
    "indices_to_plot.extend(highest_error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09db201c91015f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_new[\"date\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ed1857aac9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_id in indices_to_plot:\n",
    "    rowww = test_df_new.iloc[[index_id]]\n",
    "\n",
    "    actual_pred = rowww[target].values[0]\n",
    "\n",
    "    hist_data_temp = rowww.iloc[:, test_df_edge:].values[0]\n",
    "    # keep only samples that are in 95% confidence interval\n",
    "\n",
    "    # Plot histogram of the sampled predictions using plt\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(hist_data_temp, bins=50, alpha=0.7, label=\"NGB Predictions\")\n",
    "\n",
    "    # Plot vertical lines for actual value, mean value, and other relevant predictions\n",
    "    plt.axvline(\n",
    "        x=actual_pred,\n",
    "        color=\"black\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=\"Actual Value\",\n",
    "    )\n",
    "    plt.axvline(\n",
    "        x=rowww[\"ngb_predictions\"].values[0],\n",
    "        color=\"blue\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=\"Mean Value (NGB)\",\n",
    "    )\n",
    "    # plt.axvline(\n",
    "    #     x=rowww['predictions'].values[0],\n",
    "    #     color='red',\n",
    "    #     linestyle='dashed',\n",
    "    #     linewidth=2,\n",
    "    #     label='XGBoost Prediction'\n",
    "    # )\n",
    "\n",
    "    formatted_date = rowww[\"date\"].dt.strftime(\"%Y-%m\").values[0]\n",
    "    country_name = rowww[\"country_name\"].values[0]\n",
    "    print(formatted_date)\n",
    "    plt.title(\n",
    "        f'Histogram of NGB Predictions and Actuals for {country_name} on {formatted_date} (month_id: {int(rowww[\"month_id\"].values[0])})'\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(\n",
    "            f'{figures_prefix}/histograms/prediction_and_actuals_for_{country_name}_month_id_{int(rowww[\"month_id\"].values[0])}.png',\n",
    "            dpi=300,\n",
    "        )\n",
    "\n",
    "    if SHOW_PLOTS:\n",
    "        plt.show()\n",
    "\n",
    "if not SHOW_PLOTS:\n",
    "    plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6cb9eaafb5e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_new[test_df_new[target] == test_df_new[target].max()][\"ngb_predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1cd967007cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowww[[\"month_id\", \"country_id\", target, \"ngb_predictions\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa688bc70ed3fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce611b105eaea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions[new_predictions[\"outcome\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b712b46407d0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_color = 'blue'\n",
    "mean_line_color = \"blue\"\n",
    "actual_value_color = \"black\"\n",
    "\n",
    "# set font size bigger\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "\n",
    "\n",
    "# Define a function to plot histograms for a given instance\n",
    "def plot_histograms(instance_to_plot):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    raw_predictions = test_df_new.iloc[instance_to_plot, test_df_edge:]\n",
    "    processed_predictions = new_predictions.loc[\n",
    "        (\n",
    "            test_df_new.iloc[instance_to_plot][\"month_id\"] + prediction_window,\n",
    "            test_df_new.iloc[instance_to_plot][\"country_id\"],\n",
    "        )\n",
    "    ][[\"outcome\"]]\n",
    "    metadata = test_df_new.iloc[instance_to_plot][\n",
    "        [\"month_id\", \"country_id\", \"country_name\", \"date\", target]\n",
    "    ]\n",
    "    formatted_date = metadata[\"date\"].strftime(\"%Y-%m\")\n",
    "\n",
    "    # Set title for the row of histograms\n",
    "    # fig.suptitle(f'{metadata[\"country_name\"]} on {formatted_date} (month_id: {int(metadata[\"month_id\"])})', fontsize=16)\n",
    "\n",
    "    # Raw predictions histogram\n",
    "    raw_predictions = raw_predictions.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    raw_prediction_crps = pscore(raw_predictions, metadata[target]).compute()[0]\n",
    "\n",
    "    axs[0].hist(raw_predictions, bins=30, alpha=0.7)\n",
    "    axs[0].axvline(\n",
    "        raw_predictions.mean(), color=mean_line_color, linestyle=\"dashed\", linewidth=2\n",
    "    )\n",
    "    axs[0].axvline(metadata[target], color=actual_value_color, linewidth=2)\n",
    "    axs[0].set_title(f\"Histogram of Raw Predictions\\nCRPS: {raw_prediction_crps:.2f}\")\n",
    "    axs[0].set_xlabel(\"Predicted Values\")\n",
    "    axs[0].set_ylabel(\"Frequency\")\n",
    "    axs[0].legend(\n",
    "        [f\"Mean Value {raw_predictions.mean():.2f}\", f\"Actual Value {metadata[target]}\"]\n",
    "    )\n",
    "\n",
    "    # Processed predictions histogram\n",
    "    processed_predictions = processed_predictions.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    processed_prediction_crps = pscore(\n",
    "        processed_predictions[\"outcome\"], metadata[target]\n",
    "    ).compute()[0]\n",
    "\n",
    "    axs[1].hist(processed_predictions, bins=30, alpha=0.7)\n",
    "    axs[1].axvline(\n",
    "        processed_predictions.mean().iloc[0],\n",
    "        color=mean_line_color,\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    axs[1].axvline(metadata[target], color=actual_value_color)\n",
    "    axs[1].set_title(\n",
    "        f\"Histogram of Resampled Predictions\\nCRPS: {processed_prediction_crps:.2f}\"\n",
    "    )\n",
    "    axs[1].set_xlabel(\"Predicted Values\")\n",
    "    axs[1].legend(\n",
    "        [\n",
    "            f\"Mean Value {processed_predictions.mean().iloc[0]:.2f}\",\n",
    "            f\"Actual Value {metadata[target]}\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Raw predictions histogram with non-negative values\n",
    "    raw_predictions_non_neg = raw_predictions.clip(lower=0)\n",
    "    raw_prediction_non_neg_crps = pscore(\n",
    "        raw_predictions_non_neg, metadata[target]\n",
    "    ).compute()[0]\n",
    "    axs[2].hist(raw_predictions_non_neg, bins=30, alpha=0.7)\n",
    "    axs[2].axvline(\n",
    "        raw_predictions_non_neg.mean(),\n",
    "        color=mean_line_color,\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    axs[2].axvline(metadata[target], color=actual_value_color)\n",
    "    axs[2].set_title(\n",
    "        f\"Histogram of Clipped Predictions\\nCRPS: {raw_prediction_non_neg_crps:.2f}\"\n",
    "    )\n",
    "    axs[2].set_xlabel(\"Predicted Values\")\n",
    "    axs[2].legend(\n",
    "        [\n",
    "            f\"Mean Value {raw_predictions_non_neg.mean():.2f}\",\n",
    "            f\"Actual Value {metadata[target]}\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(\n",
    "            f'{figures_prefix}/histograms/histograms_{metadata[\"country_name\"]}_{formatted_date}.png'\n",
    "        )\n",
    "\n",
    "    if SHOW_PLOTS:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(\"all\")\n",
    "\n",
    "\n",
    "# Plot histograms for the first set of indices\n",
    "plot_histograms(indices_to_plot[8])\n",
    "\n",
    "# Plot histograms for the second set of indices\n",
    "plot_histograms(indices_to_plot[2])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
