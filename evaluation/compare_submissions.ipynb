{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# cm_features_v4 = pd.read_csv(f'data/cm_features_v0.4.csv')\n",
    "# cm_features_v5 = pd.read_csv(f'data/cm_features_v0.5.csv')\n",
    "# cm_features_v6 = pd.read_csv(f'data/cm_features_v0.6.csv')\n",
    "# print(cm_features_v4.shape)\n",
    "# print(cm_features_v5.shape)\n",
    "# print(cm_features_v6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d877b6311386d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the submission folder\n",
    "base_path = \"../submission\"\n",
    "\n",
    "# List of metrics\n",
    "metrics = ['crps', 'ign', 'mis']\n",
    "\n",
    "# Dictionary to hold all data\n",
    "all_data = {}\n",
    "\n",
    "# Process each metric\n",
    "for metric in metrics:\n",
    "    # Find all CSV files within the nested directories for each metric\n",
    "    submission_files = glob.glob(f\"{base_path}/**/{metric}.csv\", recursive=True)\n",
    "\n",
    "    # Dictionary to hold the dataframes grouped by submission name and year\n",
    "    submissions = {}\n",
    "\n",
    "    # Read each CSV file and store the dataframe in the dictionary grouped by submission name and year\n",
    "    for file in submission_files:\n",
    "        df = pd.read_csv(file)\n",
    "        parts = file.split('/')\n",
    "        submission_name = parts[2].replace('_', ' ').title()  # Adjust index based on your file path structure\n",
    "        year = parts[5].split('=')[1]  # Extract year from the 'window=YYear' part\n",
    "        if submission_name not in submissions:\n",
    "            submissions[submission_name] = {}\n",
    "        if year not in submissions[submission_name]:\n",
    "            submissions[submission_name][year] = []\n",
    "        submissions[submission_name][year].append(df['value'].mean())  # Store mean values\n",
    "\n",
    "    # Merge the metric means into the all_data dictionary\n",
    "    for submission_name, years_data in submissions.items():\n",
    "        if submission_name not in all_data:\n",
    "            all_data[submission_name] = {}\n",
    "        for year, mean_values in years_data.items():\n",
    "            if year not in all_data[submission_name]:\n",
    "                all_data[submission_name][year] = {}\n",
    "            all_data[submission_name][year][metric] = mean_values[0]  # There should be exactly one mean per metric\n",
    "\n",
    "# Convert all_data to DataFrame\n",
    "data_frames = {}\n",
    "for submission, years_data in all_data.items():\n",
    "    for year, metrics_data in years_data.items():\n",
    "        index = (submission, year)\n",
    "        data_frames[index] = metrics_data\n",
    "\n",
    "# Create a multi-index DataFrame\n",
    "result_df = pd.DataFrame.from_dict(data_frames, orient='index')\n",
    "result_df.index = pd.MultiIndex.from_tuples(result_df.index, names=['Submission', 'Year'])\n",
    "\n",
    "# Display the DataFrame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd544e67facfb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to comment this out if you have only one year, as otherwise KeyError for non-existing year is thrown\n",
    "try:\n",
    "    submissions_2018 = result_df.xs('Y2018', level='Year').sort_values(by='crps')\n",
    "except KeyError:\n",
    "    print('No 2018 data')\n",
    "    submissions_2018 = None\n",
    "submissions_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a91c57f0df011",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    submissions_2019 = result_df.xs('Y2019', level='Year').sort_values(by='crps')\n",
    "except KeyError:\n",
    "    print('No 2019 data')\n",
    "    submissions_2019 = None\n",
    "submissions_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fa55a3ff207ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    submissions_2020 = result_df.xs('Y2020', level='Year').sort_values(by='crps')\n",
    "except KeyError:\n",
    "    print('No 2020 data')\n",
    "    submissions_2020 = None\n",
    "submissions_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6722ab8bd0accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    submissions_2021 = result_df.xs('Y2021', level='Year').sort_values(by='crps')\n",
    "except KeyError:\n",
    "    print('No 2021 data')\n",
    "    submissions_2021 = None\n",
    "submissions_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f7b5a8a25e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    submissions_2022 = result_df.xs('Y2022', level='Year').sort_values(by='crps')\n",
    "except KeyError:\n",
    "    print('No 2022 data')\n",
    "    submissions_2022 = None\n",
    "submissions_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714fbd8-d739-4d12-ab16-530390b35431",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    submissions_2023 = result_df.xs('Y2023', level='Year').sort_values(by='crps')\n",
    "except KeyError:\n",
    "    print('No 2023 data')\n",
    "    submissions_2023 = None\n",
    "submissions_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462ff420dfcfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find submissions that span over all 5 years\n",
    "submissions_all_years = result_df.groupby('Submission').count()\n",
    "submissions_all_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760c645cb08c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_all_years = submissions_all_years[submissions_all_years['crps'] == 5]\n",
    "# calculate average crps, ign, mis over all years\n",
    "submissions_all_years['crps_avg'] = result_df.groupby('Submission')['crps'].mean()\n",
    "submissions_all_years['ign_avg'] = result_df.groupby('Submission')['ign'].mean()\n",
    "submissions_all_years['mis_avg'] = result_df.groupby('Submission')['mis'].mean()\n",
    "submissions_all_years = submissions_all_years.sort_values(by='crps_avg')\n",
    "\n",
    "submissions_all_years[['crps_avg', 'ign_avg', 'mis_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588af40d2a6ff668",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_FIGURES = False\n",
    "if PLOT_FIGURES:\n",
    "\n",
    "    import os\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Path to the submission folder\n",
    "    base_path = \"../submission\"\n",
    "\n",
    "    metrics = ['crps', 'ign', 'mis']\n",
    "\n",
    "    for metric in metrics:\n",
    "        # Find all CSV files within the nested directories\n",
    "        submission_files = glob.glob(f\"{base_path}/**/{metric}.csv\", recursive=True)\n",
    "        print(submission_files)\n",
    "\n",
    "        # Dictionary to hold the dataframes grouped by submission name and year\n",
    "        submissions = {}\n",
    "\n",
    "        # Read each CSV file and store the dataframe in the dictionary grouped by submission name and year\n",
    "        for file in submission_files:\n",
    "            df = pd.read_csv(file)\n",
    "            parts = file.split('/')\n",
    "            submission_name = parts[2].replace('_', ' ').title()  # Adjust index based on your file path structure\n",
    "            year = parts[5].split('=')[1]  # Extract year from the 'window=YYear' part\n",
    "            if submission_name not in submissions:\n",
    "                submissions[submission_name] = {}\n",
    "            submissions[submission_name][year] = df\n",
    "\n",
    "        # Create a figure for each submission\n",
    "        for submission_name, years_data in submissions.items():\n",
    "            num_years = len(years_data)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.suptitle(f'{metric.upper()} Histograms for {submission_name}')\n",
    "\n",
    "            # Create subplots for each year in a 2x2 grid\n",
    "            for index, (year, df) in enumerate(sorted(years_data.items()), start=1):\n",
    "                plt.subplot(2, 2, index)\n",
    "                plt.hist(df['value'], bins=100, alpha=0.75, label=f'Year: {year}')\n",
    "                mean_value = df['value'].mean()\n",
    "                plt.axvline(mean_value, color='r', linestyle='dashed', linewidth=1)\n",
    "                plt.title(f'Year: {year[1:]}')\n",
    "                plt.xlabel(metric.upper())\n",
    "                plt.ylabel('Frequency')\n",
    "                # log\n",
    "                plt.yscale('log')\n",
    "                # plt.xscale('log')\n",
    "                # mean_value = sub['value'].mean()\n",
    "                # plt.axvline(mean_value, color='r', linestyle='dashed', linewidth=1)\n",
    "                plt.legend([f'Mean: {mean_value:.1f}'])\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to not overlap with the suptitle\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79d70b-0031-4b94-abb2-9dae82afe07c",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f9ff3-c451-411b-9598-61da1c0fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years: list[str] = ['Y2018', 'Y2019', 'Y2020', 'Y2021', 'Y2022', 'Y2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5976f2-c29d-46b1-bbf8-475ee3731f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = result_df.loc[list(set([index for index in result_df.index.to_list() if 'Bm' in index[0]]))]\n",
    "predictions = result_df.loc[list(set([index for index in result_df.index.to_list() if 'Boost' in index[0]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e4fbc-ac9c-4957-906f-7723d35ed71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models: list[str] = list({index[0] for index in predictions.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc64034-276c-44ec-bbc9-45fc770bcbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_mins: list[float] = []\n",
    "\n",
    "for year in years:\n",
    "    benchmarks_year = benchmarks.loc[list(set([index for index in benchmarks.index.to_list() if index[1] == year]))]\n",
    "    benchmarks_mins.append(benchmarks_year['crps'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4751da-72e1-46f9-97d9-bf6f4aa9810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    predictions\n",
    "    .loc[\n",
    "        [index for index in predictions.index.to_list() if index[1] == 'Y2021' and index[\n",
    "            0] == 'Ng Boost Cm V2.4 Pw 14 Normal D 20 N 300 S Crpscore C F M T Bsd 5 Mbf 0.5 Dli 35 Log T']\n",
    "    ]\n",
    "    ['crps']\n",
    "    .values\n",
    "    [0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303b648-efed-4e18-b856-d39bd997019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bcb78-f0cf-4d9d-a9af-d0c84153fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores: dict[str, tuple[int, float]] = {}\n",
    "\n",
    "for model in models:\n",
    "    pred_sum: float = .0\n",
    "    score: int = 0\n",
    "    diffs: list[float] = []\n",
    "\n",
    "    for i, year in enumerate(years):\n",
    "        prediction = (\n",
    "            predictions\n",
    "            .loc[\n",
    "                [index for index in predictions.index.to_list() if index[1] == year and index[0] == model]\n",
    "            ]\n",
    "            ['crps']\n",
    "            .values\n",
    "            [0]\n",
    "        )\n",
    "\n",
    "        pred_sum += prediction\n",
    "        if prediction < benchmarks_mins[i]:\n",
    "            diffs.append(prediction - benchmarks_mins[i])\n",
    "            score += 1\n",
    "\n",
    "    scores[model] = (score, pred_sum / len(years), diffs)\n",
    "\n",
    "for model, score in zip(scores.keys(), scores.values()):\n",
    "    print('-' * 32)\n",
    "    print(model)\n",
    "    print(score)\n",
    "print('-' * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee159d01-b736-4eb6-a0ed-b181e40cb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    predictions_year = predictions.loc[list(set([index for index in predictions.index.to_list() if index[1] == year]))]\n",
    "    print(predictions_year[predictions_year['crps'] == predictions_year['crps'].min()].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea3b44-6cc0-40c5-8e33-86a4548d2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = 'Ng Boost Cm V2.5 Pw 14 Normal D 20 N 300 S Crpscore C F M T Bsd 5 Mbf 0.5 Dli 0 Log F'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be303dfe-5811-43c1-a313-9975d674df66",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71500a6d-9d84-4841-afa2-8a1d41962bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_preds: list[float] = (\n",
    "    predictions\n",
    "    .loc[[index for index in predictions.index.to_list() if index[0] == best_model]]\n",
    "    ['crps']\n",
    "    .sort_index()\n",
    "    .to_list()\n",
    ")\n",
    "best_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb996cc-831d-4a9b-9b7c-d2caca3c79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = [\n",
    "    23.4649634966269,\n",
    "    22.377350533740533,\n",
    "    32.29989332306505,\n",
    "    96.76587886250475,\n",
    "    137.1217659362756,\n",
    "    58.808471417815895\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a8c35-ca58-44d5-b5d7-561a1c308038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=pd.DataFrame([years, best_model_preds]),\n",
    "    x=pd.Series(years),\n",
    "    y=pd.Series(best_model_preds),\n",
    "    label='Best Model',\n",
    "    marker='o',\n",
    "    color=(254 / 256, 33 / 256, 139 / 256)\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=pd.DataFrame([years, news]),\n",
    "    x=pd.Series(years),\n",
    "    y=pd.Series(news),\n",
    "    label='Model Trained On High-Frequency Data',\n",
    "    marker='o',\n",
    "    color=(254 / 256, 215 / 256, 0 / 256)\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=pd.DataFrame([years, benchmarks_mins]),\n",
    "    x=pd.Series(years),\n",
    "    y=pd.Series(benchmarks_mins),\n",
    "    label='Benchmark',\n",
    "    marker='o',\n",
    "    color=(33 / 256, 176 / 256, 254 / 256)\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('CRPS')\n",
    "plt.title('CRPS Over Years')\n",
    "\n",
    "plt.savefig('../figures/best_model_over_years.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
